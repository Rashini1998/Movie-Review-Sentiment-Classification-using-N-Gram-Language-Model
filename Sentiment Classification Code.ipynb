{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55555f11-867a-47e3-a90d-4e5bf922ca54",
   "metadata": {},
   "source": [
    "<h1> Movie Review Sentiment Classification using N-Gram Language Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e2b0-e0b4-49da-92c0-32ccfda0c866",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7d7b8-ac72-4401-8e52-11312a8137c1",
   "metadata": {},
   "source": [
    "<h4>Install NLTK and scikit-learn</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47aa0c6f-66c6-41a2-9e13-a9180f583949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924a483-8f29-4b95-bc4d-da5fa058dbb7",
   "metadata": {},
   "source": [
    "<h4>Import necessary libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404c217c-9144-4ffe-94bc-ef5b6882f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce23057-e814-4ed6-be8d-19bda2d782f5",
   "metadata": {},
   "source": [
    "<h4>01) Import the movie reviews</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af9805a-1810-4f17-852c-689454d999f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Movie_Reviews.txt file\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the relative path to the uploaded file\n",
    "file_name = \"Movie_Reviews.txt\"\n",
    "relative_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# Specify the path to your \"Movie_Reviews.txt\" file\n",
    "file_path = relative_path\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "  movie_reviews = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4650c4a-863f-414f-a2f1-167aa7309f4d",
   "metadata": {},
   "source": [
    "<h4>02) Pre-process the text data</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd55afc-1c5f-4754-89c2-4df0d7955d7f",
   "metadata": {},
   "source": [
    "<h5>Split the reviews</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030fa455-4d90-4da1-95af-11d237b449c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the content into positive and negative reviews\n",
    "positive_reviews, negative_reviews = movie_reviews.split(\"Negative Reviews\\n================\")\n",
    "positive_reviews = positive_reviews.split(\"Positive Reviews\\n================\")[1].strip().split('\\n')[1:]\n",
    "negative_reviews = negative_reviews.strip().split('\\n')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5bd42-ec83-4316-9e40-3364dc462fd7",
   "metadata": {},
   "source": [
    "<h5>Preprocess a single review</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21425881-023b-4653-827e-72d2ec7eb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def preprocess_text(review):\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcec42c-e31b-4eba-81e2-872a6af6785d",
   "metadata": {},
   "source": [
    "<h4>03) Choose an appropriate value for N and implement the N-Gram model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a083b2-1317-4cee-93fc-f3bd669770d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the N for N-Grams (e.g., bigram, trigram)\n",
    "N = 2  # We can change N as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f71034-3d3d-4297-a4ac-65ba2d36ed3d",
   "metadata": {},
   "source": [
    "<p><b>Explanation:</b> The value of N is determined by the complexity of the language and the dataset. Bigrams (N=2) are a useful starting point in this scenario because they capture pairs of words and can provide context in sentiment analysis.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0f1a0-da14-43f5-9ff4-33ae53ec41f5",
   "metadata": {},
   "source": [
    "<h4>04) Calculate N-Gram probabilities for each N-Gram in the corpus</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fac718-4631-46d1-906b-c9d0c137b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    ngrams_list = list(zip(*[tokens[i:] for i in range(n)]))\n",
    "    return ngrams_list\n",
    "\n",
    "# Define a function to calculate N-Gram probabilities\n",
    "def calculate_ngram_probabilities(corpus, n):\n",
    "    ngram_counts = Counter()\n",
    "\n",
    "    for review in corpus:\n",
    "        tokens = preprocess_text(review)\n",
    "        ngrams = generate_ngrams(tokens, n)\n",
    "        ngram_counts.update(ngrams)\n",
    "\n",
    "    total_ngrams = sum(ngram_counts.values())\n",
    "    ngram_probabilities = {ngram: count / total_ngrams for ngram, count in ngram_counts.items()}\n",
    "\n",
    "    return ngram_probabilities\n",
    "\n",
    "    # Define a function to calculate the probability of a test N-gram\n",
    "def calculate_probability(test_ngram, ngram_probabilities):\n",
    "    probability = 1.0\n",
    "    for ngram in test_ngram:\n",
    "        if ngram in ngram_probabilities:\n",
    "            probability *= ngram_probabilities[ngram]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339ba16b-ac9e-493d-b486-8852def2079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Gram: ('forrest', 'gump'), Probability: 0.00398406374501992\n",
      "N-Gram: ('gump', 'absolute'), Probability: 0.00398406374501992\n",
      "N-Gram: ('absolute', 'masterpiece'), Probability: 0.00398406374501992\n",
      "N-Gram: ('masterpiece', 'tom'), Probability: 0.00398406374501992\n",
      "N-Gram: ('tom', 'hanks'), Probability: 0.00398406374501992\n",
      "N-Gram: ('hanks', 'delivers'), Probability: 0.00398406374501992\n",
      "N-Gram: ('delivers', 'unforgettable'), Probability: 0.00398406374501992\n",
      "N-Gram: ('unforgettable', 'performance'), Probability: 0.00398406374501992\n",
      "N-Gram: ('performance', 'storytelling'), Probability: 0.00398406374501992\n",
      "N-Gram: ('storytelling', 'heartwarming'), Probability: 0.00398406374501992\n",
      "N-Gram: ('heartwarming', 'movie'), Probability: 0.00398406374501992\n",
      "N-Gram: ('movie', 'journey'), Probability: 0.00398406374501992\n",
      "N-Gram: ('journey', 'life'), Probability: 0.00398406374501992\n",
      "N-Gram: ('life', 'make'), Probability: 0.00398406374501992\n",
      "N-Gram: ('make', 'laugh'), Probability: 0.00398406374501992\n",
      "N-Gram: ('laugh', 'cry'), Probability: 0.00398406374501992\n",
      "N-Gram: ('cry', 'appreciate'), Probability: 0.00398406374501992\n",
      "N-Gram: ('appreciate', 'simple'), Probability: 0.00398406374501992\n",
      "N-Gram: ('simple', 'beauties'), Probability: 0.00398406374501992\n",
      "N-Gram: ('beauties', 'existence'), Probability: 0.00398406374501992\n",
      "N-Gram: ('shawshank', 'redemption'), Probability: 0.00398406374501992\n",
      "N-Gram: ('redemption', 'timeless'), Probability: 0.00398406374501992\n",
      "N-Gram: ('timeless', 'classic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('classic', 'powerful'), Probability: 0.00398406374501992\n",
      "N-Gram: ('powerful', 'themes'), Probability: 0.00398406374501992\n",
      "N-Gram: ('themes', 'hope'), Probability: 0.00398406374501992\n",
      "N-Gram: ('hope', 'friendship'), Probability: 0.00398406374501992\n",
      "N-Gram: ('friendship', 'redemption'), Probability: 0.00398406374501992\n",
      "N-Gram: ('redemption', 'make'), Probability: 0.00398406374501992\n",
      "N-Gram: ('make', 'morgan'), Probability: 0.00398406374501992\n",
      "N-Gram: ('morgan', 'freeman'), Probability: 0.00398406374501992\n",
      "N-Gram: ('freeman', 'tim'), Probability: 0.00398406374501992\n",
      "N-Gram: ('tim', 'robbins'), Probability: 0.00398406374501992\n",
      "N-Gram: ('robbins', 'give'), Probability: 0.00398406374501992\n",
      "N-Gram: ('give', 'exceptional'), Probability: 0.00398406374501992\n",
      "N-Gram: ('exceptional', 'performances'), Probability: 0.00398406374501992\n",
      "N-Gram: ('performances', 'brilliantly'), Probability: 0.00398406374501992\n",
      "N-Gram: ('brilliantly', 'crafted'), Probability: 0.00398406374501992\n",
      "N-Gram: ('crafted', 'film'), Probability: 0.00398406374501992\n",
      "N-Gram: ('epic', 'conclusion'), Probability: 0.00398406374501992\n",
      "N-Gram: ('conclusion', 'lord'), Probability: 0.00398406374501992\n",
      "N-Gram: ('lord', 'rings'), Probability: 0.00398406374501992\n",
      "N-Gram: ('rings', 'trilogy'), Probability: 0.00398406374501992\n",
      "N-Gram: ('trilogy', 'return'), Probability: 0.00398406374501992\n",
      "N-Gram: ('return', 'king'), Probability: 0.00398406374501992\n",
      "N-Gram: ('king', 'cinematic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('cinematic', 'triumph'), Probability: 0.00398406374501992\n",
      "N-Gram: ('triumph', 'breathtaking'), Probability: 0.00398406374501992\n",
      "N-Gram: ('breathtaking', 'visuals'), Probability: 0.00398406374501992\n",
      "N-Gram: ('visuals', 'epic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('epic', 'battles'), Probability: 0.00398406374501992\n",
      "N-Gram: ('battles', 'emotionally'), Probability: 0.00398406374501992\n",
      "N-Gram: ('emotionally', 'resonant'), Probability: 0.00398406374501992\n",
      "N-Gram: ('resonant', 'story'), Probability: 0.00398406374501992\n",
      "N-Gram: ('story', 'make'), Probability: 0.00398406374501992\n",
      "N-Gram: ('make', 'monumental'), Probability: 0.00398406374501992\n",
      "N-Gram: ('monumental', 'achievement'), Probability: 0.00398406374501992\n",
      "N-Gram: ('achievement', 'filmmaking'), Probability: 0.00398406374501992\n",
      "N-Gram: ('la', 'la'), Probability: 0.00398406374501992\n",
      "N-Gram: ('la', 'land'), Probability: 0.00398406374501992\n",
      "N-Gram: ('land', 'love'), Probability: 0.00398406374501992\n",
      "N-Gram: ('love', 'letter'), Probability: 0.00398406374501992\n",
      "N-Gram: ('letter', 'magic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('magic', 'hollywood'), Probability: 0.00398406374501992\n",
      "N-Gram: ('hollywood', 'dreams'), Probability: 0.00398406374501992\n",
      "N-Gram: ('dreams', 'chemistry'), Probability: 0.00398406374501992\n",
      "N-Gram: ('chemistry', 'ryan'), Probability: 0.00398406374501992\n",
      "N-Gram: ('ryan', 'gosling'), Probability: 0.00398406374501992\n",
      "N-Gram: ('gosling', 'emma'), Probability: 0.00398406374501992\n",
      "N-Gram: ('emma', 'stone'), Probability: 0.00398406374501992\n",
      "N-Gram: ('stone', 'enchanting'), Probability: 0.00398406374501992\n",
      "N-Gram: ('enchanting', 'music'), Probability: 0.00398406374501992\n",
      "N-Gram: ('music', 'dance'), Probability: 0.00398406374501992\n",
      "N-Gram: ('dance', 'sequences'), Probability: 0.00398406374501992\n",
      "N-Gram: ('sequences', 'pure'), Probability: 0.00398406374501992\n",
      "N-Gram: ('pure', 'delight'), Probability: 0.00398406374501992\n",
      "N-Gram: ('delight', 'modern'), Probability: 0.00398406374501992\n",
      "N-Gram: ('modern', 'musical'), Probability: 0.00398406374501992\n",
      "N-Gram: ('musical', 'masterpiece'), Probability: 0.00398406374501992\n",
      "N-Gram: ('wes', 'anderson'), Probability: 0.00398406374501992\n",
      "N-Gram: ('anderson', 'whimsical'), Probability: 0.00398406374501992\n",
      "N-Gram: ('whimsical', 'style'), Probability: 0.00398406374501992\n",
      "N-Gram: ('style', 'shines'), Probability: 0.00398406374501992\n",
      "N-Gram: ('shines', 'grand'), Probability: 0.00398406374501992\n",
      "N-Gram: ('grand', 'budapest'), Probability: 0.00398406374501992\n",
      "N-Gram: ('budapest', 'hotel'), Probability: 0.00398406374501992\n",
      "N-Gram: ('hotel', 'quirky'), Probability: 0.00398406374501992\n",
      "N-Gram: ('quirky', 'characters'), Probability: 0.00398406374501992\n",
      "N-Gram: ('characters', 'colorful'), Probability: 0.00398406374501992\n",
      "N-Gram: ('colorful', 'cinematography'), Probability: 0.00398406374501992\n",
      "N-Gram: ('cinematography', 'visual'), Probability: 0.00398406374501992\n",
      "N-Gram: ('visual', 'narrative'), Probability: 0.00398406374501992\n",
      "N-Gram: ('narrative', 'delight'), Probability: 0.00398406374501992\n",
      "N-Gram: ('delight', 'film'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'charming'), Probability: 0.00398406374501992\n",
      "N-Gram: ('charming', 'delightful'), Probability: 0.00398406374501992\n",
      "N-Gram: ('delightful', 'experience'), Probability: 0.00398406374501992\n",
      "N-Gram: ('inception', 'brilliance'), Probability: 0.00398406374501992\n",
      "N-Gram: ('brilliance', 'christopher'), Probability: 0.00398406374501992\n",
      "N-Gram: ('christopher', 'nolan'), Probability: 0.00398406374501992\n",
      "N-Gram: ('nolan', 'intricate'), Probability: 0.00398406374501992\n",
      "N-Gram: ('intricate', 'plot'), Probability: 0.00398406374501992\n",
      "N-Gram: ('plot', 'stunning'), Probability: 0.00398406374501992\n",
      "N-Gram: ('stunning', 'visual'), Probability: 0.00398406374501992\n",
      "N-Gram: ('visual', 'effects'), Probability: 0.00398406374501992\n",
      "N-Gram: ('effects', 'hans'), Probability: 0.00398406374501992\n",
      "N-Gram: ('hans', 'zimmer'), Probability: 0.00398406374501992\n",
      "N-Gram: ('zimmer', 'haunting'), Probability: 0.00398406374501992\n",
      "N-Gram: ('haunting', 'score'), Probability: 0.00398406374501992\n",
      "N-Gram: ('score', 'create'), Probability: 0.00398406374501992\n",
      "N-Gram: ('create', 'cinematic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('cinematic', 'journey'), Probability: 0.00398406374501992\n",
      "N-Gram: ('journey', 'keeps'), Probability: 0.00398406374501992\n",
      "N-Gram: ('keeps', 'edge'), Probability: 0.00398406374501992\n",
      "N-Gram: ('edge', 'seat'), Probability: 0.00398406374501992\n",
      "N-Gram: ('seat', 'true'), Probability: 0.00398406374501992\n",
      "N-Gram: ('true', 'masterpiece'), Probability: 0.00398406374501992\n",
      "N-Gram: ('masterpiece', 'cinema'), Probability: 0.00398406374501992\n",
      "N-Gram: ('social', 'network'), Probability: 0.00398406374501992\n",
      "N-Gram: ('network', 'captivating'), Probability: 0.00398406374501992\n",
      "N-Gram: ('captivating', 'exploration'), Probability: 0.00398406374501992\n",
      "N-Gram: ('exploration', 'creation'), Probability: 0.00398406374501992\n",
      "N-Gram: ('creation', 'facebook'), Probability: 0.00398406374501992\n",
      "N-Gram: ('facebook', 'personal'), Probability: 0.00398406374501992\n",
      "N-Gram: ('personal', 'legal'), Probability: 0.00398406374501992\n",
      "N-Gram: ('legal', 'conflicts'), Probability: 0.00398406374501992\n",
      "N-Gram: ('conflicts', 'ensued'), Probability: 0.00398406374501992\n",
      "N-Gram: ('ensued', 'david'), Probability: 0.00398406374501992\n",
      "N-Gram: ('david', 'fincher'), Probability: 0.00398406374501992\n",
      "N-Gram: ('fincher', 'direction'), Probability: 0.00398406374501992\n",
      "N-Gram: ('direction', 'aaron'), Probability: 0.00398406374501992\n",
      "N-Gram: ('aaron', 'sorkin'), Probability: 0.00398406374501992\n",
      "N-Gram: ('sorkin', 'sharp'), Probability: 0.00398406374501992\n",
      "N-Gram: ('sharp', 'screenplay'), Probability: 0.00398406374501992\n",
      "N-Gram: ('screenplay', 'make'), Probability: 0.00398406374501992\n",
      "N-Gram: ('make', 'film'), Probability: 0.00796812749003984\n",
      "N-Gram: ('film', 'modern'), Probability: 0.00398406374501992\n",
      "N-Gram: ('modern', 'classic'), Probability: 0.00398406374501992\n",
      "N-Gram: ('smith', 'portrayal'), Probability: 0.00398406374501992\n",
      "N-Gram: ('portrayal', 'chris'), Probability: 0.00398406374501992\n",
      "N-Gram: ('chris', 'gardner'), Probability: 0.00398406374501992\n",
      "N-Gram: ('gardner', 'pursuit'), Probability: 0.00398406374501992\n",
      "N-Gram: ('pursuit', 'happyness'), Probability: 0.00398406374501992\n",
      "N-Gram: ('happyness', 'touching'), Probability: 0.00398406374501992\n",
      "N-Gram: ('touching', 'inspirational'), Probability: 0.00398406374501992\n",
      "N-Gram: ('inspirational', 'film'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'reminds'), Probability: 0.00398406374501992\n",
      "N-Gram: ('reminds', 'us'), Probability: 0.00398406374501992\n",
      "N-Gram: ('us', 'determination'), Probability: 0.00398406374501992\n",
      "N-Gram: ('determination', 'unwavering'), Probability: 0.00398406374501992\n",
      "N-Gram: ('unwavering', 'spirit'), Probability: 0.00398406374501992\n",
      "N-Gram: ('spirit', 'anyone'), Probability: 0.00398406374501992\n",
      "N-Gram: ('anyone', 'overcome'), Probability: 0.00398406374501992\n",
      "N-Gram: ('overcome', 'adversity'), Probability: 0.00398406374501992\n",
      "N-Gram: ('adversity', 'achieve'), Probability: 0.00398406374501992\n",
      "N-Gram: ('achieve', 'dreams'), Probability: 0.00398406374501992\n",
      "N-Gram: ('eternal', 'sunshine'), Probability: 0.00398406374501992\n",
      "N-Gram: ('sunshine', 'spotless'), Probability: 0.00398406374501992\n",
      "N-Gram: ('spotless', 'mind'), Probability: 0.00398406374501992\n",
      "N-Gram: ('mind', 'beautifully'), Probability: 0.00398406374501992\n",
      "N-Gram: ('beautifully', 'unconventional'), Probability: 0.00398406374501992\n",
      "N-Gram: ('unconventional', 'love'), Probability: 0.00398406374501992\n",
      "N-Gram: ('love', 'story'), Probability: 0.00398406374501992\n",
      "N-Gram: ('story', 'jim'), Probability: 0.00398406374501992\n",
      "N-Gram: ('jim', 'carrey'), Probability: 0.00398406374501992\n",
      "N-Gram: ('carrey', 'kate'), Probability: 0.00398406374501992\n",
      "N-Gram: ('kate', 'winslet'), Probability: 0.00398406374501992\n",
      "N-Gram: ('winslet', 'shine'), Probability: 0.00398406374501992\n",
      "N-Gram: ('shine', 'roles'), Probability: 0.00398406374501992\n",
      "N-Gram: ('roles', 'narrative'), Probability: 0.00398406374501992\n",
      "N-Gram: ('narrative', 'told'), Probability: 0.00398406374501992\n",
      "N-Gram: ('told', 'fashion'), Probability: 0.00398406374501992\n",
      "N-Gram: ('fashion', 'poignant'), Probability: 0.00398406374501992\n",
      "N-Gram: ('poignant', 'exploration'), Probability: 0.00398406374501992\n",
      "N-Gram: ('exploration', 'love'), Probability: 0.00398406374501992\n",
      "N-Gram: ('love', 'memories'), Probability: 0.00398406374501992\n",
      "N-Gram: ('memories', 'human'), Probability: 0.00398406374501992\n",
      "N-Gram: ('human', 'connection'), Probability: 0.00398406374501992\n",
      "N-Gram: ('princess', 'bride'), Probability: 0.00398406374501992\n",
      "N-Gram: ('bride', 'timeless'), Probability: 0.00398406374501992\n",
      "N-Gram: ('timeless', 'fairy'), Probability: 0.00398406374501992\n",
      "N-Gram: ('fairy', 'tale'), Probability: 0.00398406374501992\n",
      "N-Gram: ('tale', 'perfect'), Probability: 0.00398406374501992\n",
      "N-Gram: ('perfect', 'blend'), Probability: 0.00398406374501992\n",
      "N-Gram: ('blend', 'humor'), Probability: 0.00398406374501992\n",
      "N-Gram: ('humor', 'romance'), Probability: 0.00398406374501992\n",
      "N-Gram: ('romance', 'adventure'), Probability: 0.00398406374501992\n",
      "N-Gram: ('adventure', 'witty'), Probability: 0.00398406374501992\n",
      "N-Gram: ('witty', 'dialogue'), Probability: 0.00398406374501992\n",
      "N-Gram: ('dialogue', 'memorable'), Probability: 0.00398406374501992\n",
      "N-Gram: ('memorable', 'characters'), Probability: 0.00398406374501992\n",
      "N-Gram: ('characters', 'make'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'appeals'), Probability: 0.00398406374501992\n",
      "N-Gram: ('appeals', 'kids'), Probability: 0.00398406374501992\n",
      "N-Gram: ('kids', 'adults'), Probability: 0.00398406374501992\n",
      "N-Gram: ('adults', 'inconceivably'), Probability: 0.00398406374501992\n",
      "N-Gram: ('inconceivably', 'delightful'), Probability: 0.00398406374501992\n",
      "N-Gram: ('shades', 'grey'), Probability: 0.00398406374501992\n",
      "N-Gram: ('grey', 'managed'), Probability: 0.00398406374501992\n",
      "N-Gram: ('managed', 'captivate'), Probability: 0.00398406374501992\n",
      "N-Gram: ('captivate', 'enthusiasts'), Probability: 0.00398406374501992\n",
      "N-Gram: ('enthusiasts', 'critics'), Probability: 0.00398406374501992\n",
      "N-Gram: ('critics', 'alike'), Probability: 0.00398406374501992\n",
      "N-Gram: ('alike', 'film'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'ability'), Probability: 0.00398406374501992\n",
      "N-Gram: ('ability', 'spark'), Probability: 0.00398406374501992\n",
      "N-Gram: ('spark', 'passionate'), Probability: 0.00398406374501992\n",
      "N-Gram: ('passionate', 'discussions'), Probability: 0.00398406374501992\n",
      "N-Gram: ('discussions', 'elicit'), Probability: 0.00398406374501992\n",
      "N-Gram: ('elicit', 'wide'), Probability: 0.00398406374501992\n",
      "N-Gram: ('wide', 'range'), Probability: 0.00398406374501992\n",
      "N-Gram: ('range', 'opinions'), Probability: 0.00398406374501992\n",
      "N-Gram: ('opinions', 'testament'), Probability: 0.00398406374501992\n",
      "N-Gram: ('testament', 'impact'), Probability: 0.00398406374501992\n",
      "N-Gram: ('impact', 'may'), Probability: 0.00398406374501992\n",
      "N-Gram: ('may', 'find'), Probability: 0.00398406374501992\n",
      "N-Gram: ('find', 'controversial'), Probability: 0.00398406374501992\n",
      "N-Gram: ('controversial', 'denying'), Probability: 0.00398406374501992\n",
      "N-Gram: ('denying', 'left'), Probability: 0.00398406374501992\n",
      "N-Gram: ('left', 'significant'), Probability: 0.00398406374501992\n",
      "N-Gram: ('significant', 'mark'), Probability: 0.00398406374501992\n",
      "N-Gram: ('mark', 'world'), Probability: 0.00398406374501992\n",
      "N-Gram: ('world', 'cinema'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'conversation'), Probability: 0.00398406374501992\n",
      "N-Gram: ('conversation', 'starter'), Probability: 0.00398406374501992\n",
      "N-Gram: ('starter', 'clear'), Probability: 0.00398406374501992\n",
      "N-Gram: ('clear', 'wo'), Probability: 0.00398406374501992\n",
      "N-Gram: ('wo', 'everyone'), Probability: 0.00398406374501992\n",
      "N-Gram: ('everyone', 'cup'), Probability: 0.00398406374501992\n",
      "N-Gram: ('cup', 'tea'), Probability: 0.00398406374501992\n",
      "N-Gram: ('tea', 'willing'), Probability: 0.00398406374501992\n",
      "N-Gram: ('willing', 'approach'), Probability: 0.00398406374501992\n",
      "N-Gram: ('approach', 'open'), Probability: 0.00398406374501992\n",
      "N-Gram: ('open', 'mind'), Probability: 0.00398406374501992\n",
      "N-Gram: ('mind', 'visually'), Probability: 0.00398406374501992\n",
      "N-Gram: ('visually', 'lush'), Probability: 0.00398406374501992\n",
      "N-Gram: ('lush', 'experience'), Probability: 0.00398406374501992\n",
      "N-Gram: ('experience', 'moments'), Probability: 0.00398406374501992\n",
      "N-Gram: ('moments', 'genuine'), Probability: 0.00398406374501992\n",
      "N-Gram: ('genuine', 'chemistry'), Probability: 0.00398406374501992\n",
      "N-Gram: ('chemistry', 'leads'), Probability: 0.00398406374501992\n",
      "N-Gram: ('leads', 'film'), Probability: 0.00398406374501992\n",
      "N-Gram: ('film', 'managed'), Probability: 0.00398406374501992\n",
      "N-Gram: ('managed', 'offer'), Probability: 0.00398406374501992\n",
      "N-Gram: ('offer', 'something'), Probability: 0.00398406374501992\n",
      "N-Gram: ('something', 'different'), Probability: 0.00398406374501992\n",
      "N-Gram: ('different', 'intriguing'), Probability: 0.00398406374501992\n",
      "N-Gram: ('intriguing', 'world'), Probability: 0.00398406374501992\n",
      "N-Gram: ('world', 'romance'), Probability: 0.00398406374501992\n",
      "N-Gram: ('romance', 'drama'), Probability: 0.00398406374501992\n",
      "N-Gram: ('last', 'airbender'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('airbender', 'disaster'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('disaster', 'film'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('film', 'adaptation'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('adaptation', 'butchers'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('butchers', 'beloved'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('beloved', 'animated'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('animated', 'series'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('series', 'wooden'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('wooden', 'acting'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('acting', 'convoluted'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('convoluted', 'storytelling'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('storytelling', 'special'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('special', 'effects'), Probability: 0.013513513513513514\n",
      "N-Gram: ('effects', 'letdown'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('letdown', 'fans'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('fans', 'newcomers'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('newcomers', 'alike'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('another', 'transformers'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('transformers', 'movie'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('movie', 'mindless'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('mindless', 'explosions'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('explosions', 'incoherent'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('incoherent', 'plotlines'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('plotlines', 'overreliance'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('overreliance', 'cgi'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cgi', 'franchise'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('franchise', 'desperately'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('desperately', 'needs'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('needs', 'overhaul'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('emoji', 'movie'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('movie', 'blatant'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('blatant', 'cash'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cash', 'grab'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('grab', 'shallow'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('shallow', 'uninspired'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('uninspired', 'plot'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('plot', 'fails'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('fails', 'deliver'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('deliver', 'clever'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('clever', 'humor'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('humor', 'meaningful'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('meaningful', 'messages'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('messages', 'making'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('making', 'forgettable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('forgettable', 'disappointing'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('disappointing', 'animated'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('animated', 'film'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('fifty', 'shades'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('shades', 'grey'), Probability: 0.009009009009009009\n",
      "N-Gram: ('grey', 'attempt'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('attempt', 'romance'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('romance', 'poorly'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('poorly', 'written'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('written', 'dialogue'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('dialogue', 'unconvincing'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('unconvincing', 'chemistry'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('chemistry', 'leads'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('leads', 'make'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('make', 'awkward'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('awkward', 'unfulfilling'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('unfulfilling', 'cinematic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cinematic', 'experience'), Probability: 0.009009009009009009\n",
      "N-Gram: ('jack', 'jill'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('jill', 'unbearable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('unbearable', 'comedy'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('comedy', 'relies'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('relies', 'stale'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('stale', 'humor'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('humor', 'painfully'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('painfully', 'unfunny'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('unfunny', 'portrayal'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('portrayal', 'adam'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('adam', 'sandler'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('sandler', 'dual'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('dual', 'role'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('role', 'prime'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('prime', 'example'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('example', 'lazy'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('lazy', 'filmmaking'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('superman', 'iv'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('iv', 'colossal'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('colossal', 'disappointment'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('disappointment', 'marred'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('marred', 'low'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('low', 'budget'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('budget', 'laughable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('laughable', 'special'), Probability: 0.009009009009009009\n",
      "N-Gram: ('effects', 'poorly'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('poorly', 'conceived'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('conceived', 'story'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('story', 'even'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('even', 'christopher'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('christopher', 'reeve'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('reeve', 'charm'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('charm', 'ca'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('ca', 'save'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('save', 'mess'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cat', 'hat'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('hat', 'chaotic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('chaotic', 'misguided'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('misguided', 'adaptation'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('adaptation', 'seuss'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('seuss', 'classic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('classic', 'sacrifices'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('sacrifices', 'charm'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('charm', 'simplicity'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('simplicity', 'source'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('source', 'material'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('material', 'crude'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('crude', 'humor'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('humor', 'lackluster'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('lackluster', 'narrative'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('room', 'widely'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('widely', 'regarded'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('regarded', 'one'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('one', 'worst'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('worst', 'films'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('films', 'ever'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('ever', 'made'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('made', 'disjointed'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('disjointed', 'plot'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('plot', 'stilted'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('stilted', 'acting'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('acting', 'bizarre'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('bizarre', 'dialogue'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('dialogue', 'turned'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('turned', 'cult'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cult', 'classic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('classic', 'right'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('right', 'reasons'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('battlefield', 'earth'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('earth', 'disaster'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('disaster', 'convoluted'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('convoluted', 'mess'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('mess', 'hammy'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('hammy', 'acting'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('acting', 'laughable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('effects', 'film'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('film', 'remained'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('remained', 'buried'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('buried', 'annals'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('annals', 'cinematic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cinematic', 'history'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('gigli', 'train'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('train', 'wreck'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('wreck', 'romantic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('romantic', 'comedy'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('comedy', 'pairing'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('pairing', 'ben'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('ben', 'affleck'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('affleck', 'jennifer'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('jennifer', 'lopez'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('lopez', 'devoid'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('devoid', 'chemistry'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('chemistry', 'dialogue'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('dialogue', 'cringeworthy'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cringeworthy', 'embarrassing'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('embarrassing', 'misstep'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('misstep', 'careers'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('grey', 'film'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('film', 'divided'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('divided', 'enthusiasts'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('enthusiasts', 'critics'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('critics', 'share'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('share', 'devoted'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('devoted', 'fans'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('fans', 'also'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('also', 'faces'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('faces', 'substantial'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('substantial', 'criticism'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('criticism', 'film'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('film', 'content'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('content', 'execution'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('execution', 'leave'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('leave', 'much'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('much', 'desired'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('desired', 'making'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('making', 'polarizing'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('polarizing', 'cinematic'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('experience', 'viewer'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('viewer', 'reactions'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('reactions', 'may'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('may', 'vary'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('vary', 'widely'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('widely', 'movie'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('movie', 'evokes'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('evokes', 'strong'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('strong', 'opinions'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('opinions', 'ends'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('ends', 'spectrum'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('film', 'portrayal'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('portrayal', 'relationships'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('relationships', 'themes'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('themes', 'may'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('may', 'leave'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('leave', 'many'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('many', 'viewers'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('viewers', 'uncomfortable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('uncomfortable', 'tests'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('tests', 'limits'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('limits', 'may'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('may', 'find'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('find', 'acceptable'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('acceptable', 'mainstream'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('mainstream', 'cinema'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('cinema', 'idea'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('idea', 'keeping'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('keeping', 'open'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('open', 'mind'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('mind', 'essential'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('essential', 'particular'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('particular', 'movie'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('movie', 'might'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('might', 'push'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('push', 'openness'), Probability: 0.0045045045045045045\n",
      "N-Gram: ('openness', 'boundaries'), Probability: 0.0045045045045045045\n"
     ]
    }
   ],
   "source": [
    "positive_ngram_probabilities = calculate_ngram_probabilities(positive_reviews, N)\n",
    "negative_ngram_probabilities = calculate_ngram_probabilities(negative_reviews, N)\n",
    "for ngram, probability in positive_ngram_probabilities.items():\n",
    "    print(f\"N-Gram: {ngram}, Probability: {probability}\")\n",
    "for ngram, probability in negative_ngram_probabilities.items():\n",
    "    print(f\"N-Gram: {ngram}, Probability: {probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a35212-a3e4-4807-ab4e-9cf9b5e91923",
   "metadata": {},
   "source": [
    "<h4>05) Calculate the N-gram probability for given test movie review</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db5fe1a-ff23-4d50-890a-c829c096002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Probability:  1.5872763924382153e-05\n",
      "Negative Probability:  2.029056083110137e-05\n"
     ]
    }
   ],
   "source": [
    "# Calculate N-Gram probabilities for the test review\n",
    "test_review = \"It's clear that the movie has both its enthusiasts and critics. While it may not be to everyone's taste, it's worth watching with an open mind to form your own opinion.\"\n",
    "test_tokens = preprocess_text(test_review)\n",
    "test_bigrams =generate_ngrams(test_tokens,N)\n",
    "\n",
    "# Calculate N-Gram probabilities for the test review\n",
    "positive_probability = calculate_probability(test_bigrams, positive_ngram_probabilities )\n",
    "negative_probability = calculate_probability(test_bigrams, negative_ngram_probabilities )\n",
    "print(\"Positive Probability: \", positive_probability)\n",
    "print(\"Negative Probability: \",negative_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae032a4-9c3a-4629-85d5-6eb91682a301",
   "metadata": {},
   "source": [
    "<h4>06) Predict the category of the test movie review</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3330ca1-170b-45a4-a0c7-d4d657557013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Determine the sentiment\n",
    "sentiment = \"positive\" if positive_probability >= negative_probability else \"negative\"\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe00a09-1dec-418c-8162-6354b9f1ef41",
   "metadata": {},
   "source": [
    "<p><b>Explanation: </b>According to the algorithm's analysis of the test movie review, it falls into the \"Negative\" category. This conclusion is based on the computed probabilities, which reveal that negative is more likely than positivity.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db3a68-5404-4a04-ada0-60570291bacd",
   "metadata": {},
   "source": [
    "<h4>07) Explain the concept of perplexity and how it measures the model's performance</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9900d-13d8-4b1b-bd83-71c0f91eddce",
   "metadata": {},
   "source": [
    "<p>Perplexity is a metric that measures how effectively any language model predicts a given word sequence. Low perplexity suggests improved model performance.The inverse of the average probability of the following word given the preceding words is used to compute it. Perplexity can be used to compare and evaluate alternative language models.\r\n",
    "\r\n",
    "The following formula can be used to calculate perplexity<b>: PPL = 2^(-log2(likelihood</b>)).\r\n",
    "\r\n",
    "According to the model, likelihood is the log-likelihood of the test data. The log2 function logarithmically scales the likelihood. T 2^-x-x factor returns the logarithmic value to the probability scal Perplexity is a measure of how well an N-Gram model predicts the next word based on the previous N-1 words. A lower perplexity suggests that the model is more accurate in anticipating the next word and, as a result, better at understanding the language. It is a standard statistic for evaluating language models.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
